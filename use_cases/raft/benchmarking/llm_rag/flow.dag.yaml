id: bring_your_own_data_chat_qna
name: Bring Your Own Data Chat QnA
inputs:
  chat_history:
    type: list
    default:
    - inputs:
        chat_input: Hi
      outputs:
        chat_output: Hello! How can I assist you today?
    - inputs:
        chat_input: What is Azure compute instance?
      outputs:
        chat_output: An Azure Machine Learning compute instance is a fully managed
          cloud-based workstation for data scientists. It provides a
          pre-configured and managed development environment in the cloud for
          machine learning. Compute instances can also be used as a compute
          target for training and inferencing for development and testing
          purposes. They have a job queue, run jobs securely in a virtual
          network environment, and can run multiple small jobs in parallel.
          Additionally, compute instances support single-node multi-GPU
          distributed training jobs.
    is_chat_input: false
    is_chat_history: true
  chat_input:
    type: string
    default: How can I create one using azureml sdk V2?
    is_chat_input: true
outputs:
  chat_output:
    type: string
    reference: ${get_final_output.output}
    is_chat_output: true
nodes:
- name: modify_query_with_history
  type: llm
  source:
    type: code
    path: modify_query_with_history.jinja2
  inputs:
    deployment_name: gpt4omini
    temperature: 0
    top_p: 1
    max_tokens: 1000
    response_format:
      type: text
    presence_penalty: 0
    frequency_penalty: 0
    chat_history: ${inputs.chat_history}
    chat_input: ${inputs.chat_input}
  provider: AzureOpenAI
  connection: aoi
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
- name: lookup
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.common_index_lookup.search
  inputs:
    mlindex_content: >
      embeddings:
        api_base: https://aoi-meemank.openai.azure.com/
        api_type: azure
        api_version: '2024-02-01'
        batch_size: '1'
        connection:
          id: /subscriptions/62a476f9-9f3d-443f-991f-c2970691f3c9/resourceGroups/rg-meemankgpt/providers/Microsoft.MachineLearningServices/workspaces/ws-meemankraft/connections/aoi
        connection_type: workspace_connection
        deployment: embedding
        dimension: 1536
        kind: open_ai
        model: text-embedding-ada-002
        schema_version: '2'
      index:
        api_version: '2023-11-01'
        connection:
          id: /subscriptions/62a476f9-9f3d-443f-991f-c2970691f3c9/resourceGroups/rg-meemankgpt/providers/Microsoft.MachineLearningServices/workspaces/ws-meemankraft/connections/ai_search
        connection_type: workspace_connection
        endpoint: https://ai-mmk.search.windows.net
        engine: azure-sdk
        field_mapping:
          content: content
          embedding: contentVector
          metadata: title
        index: plum-camel-m8rln98tqx
        kind: acs
        semantic_configuration_name: azureml-default
    queries: ${modify_query_with_history.output}
    query_type: Hybrid (vector + keyword)
    top_k: 3
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${lookup.output}
  use_variants: false
- name: Prompt_variants
  use_variants: true
- name: chat_with_context
  type: llm
  source:
    type: code
    path: chat_with_context.jinja2
  inputs:
    deployment_name: gpt4omini
    temperature: 0
    top_p: 1
    max_tokens: 1000
    response_format:
      type: text
    presence_penalty: 0
    frequency_penalty: 0
    prompt_text: ${Prompt_variants.output}
  provider: AzureOpenAI
  connection: aoi
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
- name: get_final_output
  type: python
  source:
    type: code
    path: get_final_output.py
  inputs:
    rag_response: ${chat_with_context.output}
    source_documents: ${lookup.output}
    user_question: ${inputs.chat_input}
  use_variants: false
node_variants:
  Prompt_variants:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            chat_history: ${inputs.chat_history}
            chat_input: ${inputs.chat_input}
      variant_1:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__variant_1.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            chat_history: ${inputs.chat_history}
            chat_input: ${inputs.chat_input}
      variant_2:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__variant_2.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            chat_history: ${inputs.chat_history}
            chat_input: ${inputs.chat_input}
environment:
  python_requirements_txt: requirements.txt
