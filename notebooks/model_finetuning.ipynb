{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807355d8-01a2-4082-9dd9-822e026348a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires Python 3.10 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cde469-d817-462c-8f3c-be5636bde42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0c5834-94e4-448f-b113-ee2cd94d93c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405773d7-9a83-4dee-a10f-4985bc024aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-08 18:34:39.719872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 18:34:40.601372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 18:34:40.875744: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 18:34:42.884907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 18:34:46.985586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "import torch\n",
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AwqConfig\n",
    "\n",
    "from onnxruntime_genai.models.builder import create_model\n",
    "import onnxruntime_genai as og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63aee57f-df19-4dac-9441-a9ff3cf5bd08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"finetuning_experiment\"\n",
    "output_name = \"model_dir\"\n",
    "output_directory = \"./models\"\n",
    "finetuned_model_path = f\"{output_directory}/named-outputs/model_dir/merged\"\n",
    "finetuned_quantized_awq_model_path = f\"{output_directory}/named-outputs/model_dir/merged-awq\"\n",
    "finetuned_quantized_onnx_model_path = f\"{output_directory}/named-outputs/model_dir/merged-onnx\"\n",
    "finetuned_quantized_awq_to_onnx_model_path = f\"{output_directory}/named-outputs/model_dir/merged-awq-onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8612df-2ceb-49ef-a6e2-c125ce2b72b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_output_onnx(model, tokenizer, prompt):\n",
    "    tokenizer_stream = tokenizer.create_stream()\n",
    "    input_tokens = tokenizer.encode(prompt)\n",
    "    \n",
    "    search_options = {\n",
    "        \"max_length\": 2048, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False\n",
    "    }\n",
    "\n",
    "    params = og.GeneratorParams(model)\n",
    "    params.set_search_options(**search_options)\n",
    "    params.input_ids = input_tokens\n",
    "    generator = og.Generator(model, params)\n",
    "    \n",
    "    started_timestamp = time.time()\n",
    "\n",
    "    first = True\n",
    "    new_tokens = []\n",
    "    new_tokens_decoded = []\n",
    "\n",
    "    while not generator.is_done():\n",
    "        generator.compute_logits()\n",
    "        generator.generate_next_token()\n",
    "        if first:\n",
    "            first_token_timestamp = time.time()\n",
    "            first = False\n",
    "        new_token = generator.get_next_tokens()[0]\n",
    "        new_token_decoded = tokenizer_stream.decode(new_token)\n",
    "        print(new_token_decoded, end='', flush=True)\n",
    "        new_tokens.append(new_token)\n",
    "        new_tokens_decoded.append(new_token_decoded)\n",
    "    \n",
    "    prompt_length = len(input_tokens)\n",
    "    new_tones_length = len(new_tokens)\n",
    "    first_token_time = first_token_timestamp - started_timestamp\n",
    "    run_time = time.time() - first_token_timestamp\n",
    "    prompt_tokens_per_second = len(input_tokens)/first_token_time\n",
    "    new_tokens_per_second = len(new_tokens)/run_time\n",
    "    \n",
    "    generated_output = \"\".join(new_tokens_decoded)\n",
    "    \n",
    "    del generator\n",
    "        \n",
    "    return generated_output, first_token_time, run_time, prompt_tokens_per_second, new_tokens_per_second\n",
    "\n",
    "def get_formatted_context(chunks):\n",
    "    BEGIN = \"<DOCUMENT>\"\n",
    "    END = \"</DOCUMENT>\"\n",
    "    NEW_LINE = \"\\n\"\n",
    "\n",
    "    context = [f\"{BEGIN}{chunk}{END}{NEW_LINE}\" for chunk in chunks]\n",
    "    return \"\".join(context)\n",
    "\n",
    "\n",
    "def get_chat_template_input(meta_prompt, context, query):\n",
    "    messages = [\n",
    "        {\"content\": meta_prompt, \"role\": \"system\"},\n",
    "        {\"content\": f\"{context}{query}.\", \"role\": \"user\"}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f353a7-2f10-4969-b3bd-e71b788a28e4",
   "metadata": {},
   "source": [
    "# Substitute \"merged\" with new transformer model trained with new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70985703-1105-43a5-9ce1-235a5a20b256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    if not os.listdir(output_directory):   \n",
    "        try:\n",
    "            credential = DefaultAzureCredential()\n",
    "            credential.get_token(\"https://management.azure.com/.default\")\n",
    "        except Exception as ex:\n",
    "            # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "            # This will open a browser page for\n",
    "            credential = InteractiveBrowserCredential()\n",
    "            \n",
    "        ml_client = MLClient.from_config(\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        jobs = ml_client.jobs.list()\n",
    "\n",
    "        filtered_jobs = [job for job in jobs if job.experiment_name == experiment_name]\n",
    "        print(filtered_jobs[-1])\n",
    "        \n",
    "        job_name = filtered_jobs[-1].name\n",
    "        ml_client.jobs.download(name=job_name, output_name=output_name, download_path=output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88089e57-8569-49ac-b88d-cd13859b70a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantize_model(model_path, quant_path, output_path, execution_provider, use_qdq):\n",
    "    quant_config = { \"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\" }\n",
    "\n",
    "    # Load model\n",
    "    model = AutoAWQForCausalLM.from_pretrained(\n",
    "        model_path, **{\"low_cpu_mem_usage\": True, \"use_cache\": False}\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "    # Quantize model\n",
    "    model.quantize(tokenizer, quant_config=quant_config)\n",
    "\n",
    "    # Save quantized model\n",
    "    model.save_quantized(quant_path)\n",
    "    tokenizer.save_pretrained(quant_path)\n",
    "\n",
    "    print(f'Model is quantized and saved at \"{quant_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ad70f9-2ff7-43d3-abb7-93129ef22b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = f\"{output_directory}/named-outputs/model_dir/merged\"\n",
    "quant_path = f\"{output_directory}/named-outputs/model_dir/merged-awq\"\n",
    "output_path = f\"{output_directory}/named-outputs/model_dir/merged-awq-onnx\"\n",
    "\n",
    "execution_provider = \"cpu\"\n",
    "use_qdq = True\n",
    "\n",
    "model_name = None\n",
    "input_folder = quant_path\n",
    "output_folder = output_path\n",
    "precision = \"int4\"\n",
    "cache_dir = os.path.join(\".\", \"cache_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc125f3-497e-44d3-8e8c-16f19c42fe67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 18:39:30,195 transformers_modules.microsoft.Phi-3-mini-128k-instruct.a90b62ae09941edff87a90ced39ba5807e6b2ade.modeling_phi3 [WARNING] - `flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "2024-10-08 18:39:30,195 transformers_modules.microsoft.Phi-3-mini-128k-instruct.a90b62ae09941edff87a90ced39ba5807e6b2ade.modeling_phi3 [WARNING] - Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:49<00:00, 12.50s/it]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-10-08 18:40:20,847 huggingface_hub.repocard [WARNING] - Repo card metadata block was not found. Setting CardData to empty.\n",
      "AWQ:   0%|          | 0/32 [00:00<?, ?it/s]2024-10-08 18:40:27,049 transformers_modules.microsoft.Phi-3-mini-128k-instruct.a90b62ae09941edff87a90ced39ba5807e6b2ade.modeling_phi3 [WARNING] - You are not running the flash-attention implementation, expect numerical differences.\n",
      "AWQ: 100%|██████████| 32/32 [08:55<00:00, 16.73s/it]\n",
      "Note that `shard_checkpoint` is deprecated and will be removed in v4.44. We recommend you using split_torch_state_dict_into_shards from huggingface_hub library\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is quantized and saved at \"./models/named-outputs/model_dir/merged-awq\"\n"
     ]
    }
   ],
   "source": [
    "quantize_model(model_path, quant_path, output_path, execution_provider, use_qdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc2f3da-2dd8-4477-9631-b6828908ee56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupQueryAttention (GQA) is used in this model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:957: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking and repacking layer 0\n",
      "Unpacking and repacking layer 1\n",
      "Unpacking and repacking layer 2\n",
      "Unpacking and repacking layer 3\n",
      "Unpacking and repacking layer 4\n",
      "Unpacking and repacking layer 5\n",
      "Unpacking and repacking layer 6\n",
      "Unpacking and repacking layer 7\n",
      "Unpacking and repacking layer 8\n",
      "Unpacking and repacking layer 9\n",
      "Unpacking and repacking layer 10\n",
      "Unpacking and repacking layer 11\n",
      "Unpacking and repacking layer 12\n",
      "Unpacking and repacking layer 13\n",
      "Unpacking and repacking layer 14\n",
      "Unpacking and repacking layer 15\n",
      "Unpacking and repacking layer 16\n",
      "Unpacking and repacking layer 17\n",
      "Unpacking and repacking layer 18\n",
      "Unpacking and repacking layer 19\n",
      "Unpacking and repacking layer 20\n",
      "Unpacking and repacking layer 21\n",
      "Unpacking and repacking layer 22\n",
      "Unpacking and repacking layer 23\n",
      "Unpacking and repacking layer 24\n",
      "Unpacking and repacking layer 25\n",
      "Unpacking and repacking layer 26\n",
      "Unpacking and repacking layer 27\n",
      "Unpacking and repacking layer 28\n",
      "Unpacking and repacking layer 29\n",
      "Unpacking and repacking layer 30\n",
      "Unpacking and repacking layer 31\n",
      "Reading embedding layer\n",
      "Reading decoder layer 0\n",
      "Reading decoder layer 1\n",
      "Reading decoder layer 2\n",
      "Reading decoder layer 3\n",
      "Reading decoder layer 4\n",
      "Reading decoder layer 5\n",
      "Reading decoder layer 6\n",
      "Reading decoder layer 7\n",
      "Reading decoder layer 8\n",
      "Reading decoder layer 9\n",
      "Reading decoder layer 10\n",
      "Reading decoder layer 11\n",
      "Reading decoder layer 12\n",
      "Reading decoder layer 13\n",
      "Reading decoder layer 14\n",
      "Reading decoder layer 15\n",
      "Reading decoder layer 16\n",
      "Reading decoder layer 17\n",
      "Reading decoder layer 18\n",
      "Reading decoder layer 19\n",
      "Reading decoder layer 20\n",
      "Reading decoder layer 21\n",
      "Reading decoder layer 22\n",
      "Reading decoder layer 23\n",
      "Reading decoder layer 24\n",
      "Reading decoder layer 25\n",
      "Reading decoder layer 26\n",
      "Reading decoder layer 27\n",
      "Reading decoder layer 28\n",
      "Reading decoder layer 29\n",
      "Reading decoder layer 30\n",
      "Reading decoder layer 31\n",
      "Reading final norm\n",
      "Reading LM head\n",
      "Saving ONNX model in ./models/named-outputs/model_dir/merged-awq-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:924: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:785: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving GenAI config in ./models/named-outputs/model_dir/merged-awq-onnx\n",
      "Saving processing files in ./models/named-outputs/model_dir/merged-awq-onnx for GenAI\n"
     ]
    }
   ],
   "source": [
    "extra_options = {\n",
    "    \"use_qdq\": use_qdq,\n",
    "}\n",
    "\n",
    "create_model(model_name, input_folder, output_folder, precision, execution_provider, cache_dir, **extra_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959942c-460b-4315-9be7-21ad20887778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a2e34d-1a08-4edb-842e-d83178c90a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnxruntime_genai as og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f50f535-170a-49ac-8d93-e3e37d1416ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nThe following is a conversation with an AI assistant. The assistant is helpful, clever, friendly and gives concise and accurate answers.<|end|>\\n<|user|>\\n<DOCUMENT>Various. Verify the error codes in the balance’s manual.MAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n29BASIC DEFINITIONS\\nASTM. American Society of Testing and Materials.</DOCUMENT>\\n<DOCUMENT>Preventive maintenance\\nFrequency: Quarterly1. Verify the stability of the lamp. Use the calibration plate, \\nconducting readings with intervals of 30 minutes with the same plate. Compare readings. There must be no diff erences.</DOCUMENT>\\n<DOCUMENT>2. A measuring device known as “load cell” produces an \\nexit signal corresponding to the load’s force in the form of changes in the voltage or frequency. 3. A digital analogous electronic circuit shows the fi  nal \\nresult of the weight digitally. Laboratory balances operate according to the principle \\nof compensation of the electromagnetic force applicable to displacements or torques. The combination of their mechanical components and automatic reading systems provides weight measurements at defi  ned levels of accuracy \\ndepending on the model. Principle. The mobile parts (weighing plate, support \\ncolumn [a], bobbin, position and load indicator [G] -the object in the process of being weighed-) are maintained in equilibrium by a compensation force [F] equal to the weight. The compensation force is generated by an electrical current through a bobbin in the air gap of a cylindrical electromagnet. The force F is calculated with the equation [F = I x L x B] where: I = electrical intensity, L = total length of the wire of the coil and B = magnetic fl  ow intensity in the \\nelectromagnet’s air gap.With any change in the load (weight\\\\/mass), the mobile \\nmechanical system responds by moving vertically a fraction of distance. Detected by a photosensor [e], an electrical signal is sent to the servo-amplifi  er [f]. This changes the \\nfl ow of electrical current passing through the bobbin of the \\nmagnet [c] in such a manner that the mobile system returns to the balanced position upon adjusting of the magnetic fl ow in the electromagnet. Consequently, the weight of \\nthe mass [G] can be measured indirectly at the start of the electrical current fl  ow, which passes through the circuit \\nmeasuring the voltage [V] by means of a precision resistor [R], [V = I x R]. To date, many systems developed use the electronic system for carrying out very exact measurements of mass and weight. The following diagram explains how electronic balances function. Transfer\\nMechanism\\nLoad Cell\\nScreen and\\nSignal ProcessorPFigure 12. Components of electronic balances  \\nG\\nb\\na\\ne\\nfc dR V=I*R\\nIFigure 13. Compensation force principle  \\nMAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n25The signal processing system\\nThe signal processing system is composed of the circuit which \\ntransf orms the electrical signal emitted by the transducer \\ninto numerical data which can be read on a screen. The signal process comprises the following functions:1. Tare setting. This setting is used to adjust the reading \\nvalue at zero with any load within the balance’s capacity range. It is controlled by a button generally located on the front part of the balance. It is commonly used for taring the weighing container. 2. Repeatability setting control. During a reading, weighed \\nvalues are averaged within a predefi  ned period of time. This function is very useful when weighing operations need to be carried out in unstable conditions, e.g. in the presence of air currents or vibrations. This control defi nes the time period allowed for a result to lie within \\npreset limits for it to be considered stable. In addition, it can be adjusted to suit a particular application.</DOCUMENT>\\n<DOCUMENT>Any spill must be cleaned immediately to avoid corrosion \\nor contamination. Use 70% ethanol to disinfect the pan of the balance. Very important:  Never lubricate a balance unless the \\nmanufacturer has expressly indicated it. Any substance interfering with the mechanism of the balance retards its response or defi  nitely alters the measurement process. Note:  In general, the manufacturer or the specialized \\ninstallation representative carries out the maintenance of the balances, according to procedures which vary depending on the type and model. 1 Guidelines for calibration in laboratories, Drinking Water Inspectorate by \\nLGC (Teddington) Ltd., December 2000. CapacityResolution\\n100 g 10 g 1 g 100 mg 10 mg 1 mg 0.1 mg \\x980.01 mg \\nUp to 200 g – – – M1 M1 F2 F1 F2\\n200 g to 1 kg – – M1 M1 F2 F1\\\\/E2 E2 E2\\n1 to 30 kg M2 M2 M1 F2 E2 E2 E2 –\\n30 to 100 kg M2 M1 F2 F1 E2 – – –\\nMore than \\n100 kgM2 M1\\\\/F2 F1 E2 – – – –Table of standard weights’ use according to the balance’s capacity  CHAPTER 4  BALANCES\\n28FUNCTIONAL ERROR PROBABLE CAUSE\\nReadings not reproducible (hysteresis). The measurement cell is dirty.</DOCUMENT>\\n<DOCUMENT>Check the lubrication state of elements such as for \\nO-rings as the manufacturer recommends. Always use lubricants according to the manufacturer’s instructions (frequency and type of lubricants). In recently manufactured centrifuges, there are sealed ball bearings which do not require lubrication. 5.</DOCUMENT>\\n<DOCUMENT>Remove the cover of the boiling tank.3. Visually verify if the interior walls or the immersion \\nresistors show solid deposits or sediments. The quantity of deposits present depends on the quality of water fed to the distiller. If there is an accumulation of sediments, it must be cleaned to avoid damaging the resistors\\n1. 4.</DOCUMENT>\\nWhat does ASTM stand for?<|end|>\\n<|assistant|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt(chat_template, meta_prompt, query, context):\n",
    "    prompt = f'{chat_template.format(meta_prompt=meta_prompt, context=context, query=query)}'\n",
    "    return prompt\n",
    "\n",
    "meta_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, clever, friendly and gives concise and accurate answers.\"\n",
    "chunks = [\n",
    "    \"Various. Verify the error codes in the balance\\u2019s manual.MAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n29BASIC DEFINITIONS\\nASTM. American Society of Testing and Materials.\",\n",
    "    \"Preventive maintenance\\nFrequency: Quarterly1. Verify the stability of the lamp. Use the calibration plate, \\nconducting readings with intervals of 30 minutes with the same plate. Compare readings. There must be no diff erences.\",\n",
    "    \"2. A measuring device known as \\u201cload cell\\u201d produces an \\nexit signal corresponding to the load\\u2019s force in the form of changes in the voltage or frequency. 3. A digital analogous electronic circuit shows the fi  nal \\nresult of the weight digitally. Laboratory balances operate according to the principle \\nof compensation of the electromagnetic force applicable to displacements or torques. The combination of their mechanical components and automatic reading systems provides weight measurements at defi  ned levels of accuracy \\ndepending on the model. Principle. The mobile parts (weighing plate, support \\ncolumn [a], bobbin, position and load indicator [G] -the object in the process of being weighed-) are maintained in equilibrium by a compensation force [F] equal to the weight. The compensation force is generated by an electrical current through a bobbin in the air gap of a cylindrical electromagnet. The force F is calculated with the equation [F = I x L x B] where: I = electrical intensity, L = total length of the wire of the coil and B = magnetic fl  ow intensity in the \\nelectromagnet\\u2019s air gap.With any change in the load (weight\\/mass), the mobile \\nmechanical system responds by moving vertically a fraction of distance. Detected by a photosensor [e], an electrical signal is sent to the servo-amplifi  er [f]. This changes the \\nfl ow of electrical current passing through the bobbin of the \\nmagnet [c] in such a manner that the mobile system returns to the balanced position upon adjusting of the magnetic fl ow in the electromagnet. Consequently, the weight of \\nthe mass [G] can be measured indirectly at the start of the electrical current fl  ow, which passes through the circuit \\nmeasuring the voltage [V] by means of a precision resistor [R], [V = I x R]. To date, many systems developed use the electronic system for carrying out very exact measurements of mass and weight. The following diagram explains how electronic balances function. Transfer\\nMechanism\\nLoad Cell\\nScreen and\\nSignal ProcessorPFigure 12. Components of electronic balances  \\nG\\nb\\na\\ne\\nfc dR V=I*R\\nIFigure 13. Compensation force principle  \\nMAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n25The signal processing system\\nThe signal processing system is composed of the circuit which \\ntransf orms the electrical signal emitted by the transducer \\ninto numerical data which can be read on a screen. The signal process comprises the following functions:1. Tare setting. This setting is used to adjust the reading \\nvalue at zero with any load within the balance\\u2019s capacity range. It is controlled by a button generally located on the front part of the balance. It is commonly used for taring the weighing container. 2. Repeatability setting control. During a reading, weighed \\nvalues are averaged within a predefi  ned period of time. This function is very useful when weighing operations need to be carried out in unstable conditions, e.g. in the presence of air currents or vibrations. This control defi nes the time period allowed for a result to lie within \\npreset limits for it to be considered stable. In addition, it can be adjusted to suit a particular application.\",\n",
    "    \"Any spill must be cleaned immediately to avoid corrosion \\nor contamination. Use 70% ethanol to disinfect the pan of the balance. Very important:  Never lubricate a balance unless the \\nmanufacturer has expressly indicated it. Any substance interfering with the mechanism of the balance retards its response or defi  nitely alters the measurement process. Note:  In general, the manufacturer or the specialized \\ninstallation representative carries out the maintenance of the balances, according to procedures which vary depending on the type and model. 1 Guidelines for calibration in laboratories, Drinking Water Inspectorate by \\nLGC (Teddington) Ltd., December 2000. CapacityResolution\\n100 g 10 g 1 g 100 mg 10 mg 1 mg 0.1 mg \\u00980.01 mg \\nUp to 200 g \\u2013 \\u2013 \\u2013 M1 M1 F2 F1 F2\\n200 g to 1 kg \\u2013 \\u2013 M1 M1 F2 F1\\/E2 E2 E2\\n1 to 30 kg M2 M2 M1 F2 E2 E2 E2 \\u2013\\n30 to 100 kg M2 M1 F2 F1 E2 \\u2013 \\u2013 \\u2013\\nMore than \\n100 kgM2 M1\\/F2 F1 E2 \\u2013 \\u2013 \\u2013 \\u2013Table of standard weights\\u2019 use according to the balance\\u2019s capacity  CHAPTER 4  BALANCES\\n28FUNCTIONAL ERROR PROBABLE CAUSE\\nReadings not reproducible (hysteresis). The measurement cell is dirty.\",\n",
    "    \"Check the lubrication state of elements such as for \\nO-rings as the manufacturer recommends. Always use lubricants according to the manufacturer\\u2019s instructions (frequency and type of lubricants). In recently manufactured centrifuges, there are sealed ball bearings which do not require lubrication. 5.\",\n",
    "    \"Remove the cover of the boiling tank.3. Visually verify if the interior walls or the immersion \\nresistors show solid deposits or sediments. The quantity of deposits present depends on the quality of water fed to the distiller. If there is an accumulation of sediments, it must be cleaned to avoid damaging the resistors\\n1. 4.\"\n",
    "]\n",
    "context = get_formatted_context(chunks)\n",
    "query = \"What does ASTM stand for?\"\n",
    "chat_template = \"<|system|>\\n{meta_prompt}<|end|>\\n<|user|>\\n{context}{query}<|end|>\\n<|assistant|>\"\n",
    "\n",
    "prompt = create_prompt(chat_template, meta_prompt, query, context)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3b1fea-281e-43d3-939a-ce1edcdb853e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(output_path):\n",
    "    model = og.Model(output_path)\n",
    "    tokenizer = og.Tokenizer(model)    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def run_model(model, tokenizer, prompt):\n",
    "    tokenizer_stream = tokenizer.create_stream()\n",
    "\n",
    "    # Override any default search options in `genai_config.json`\n",
    "    search_options = {\n",
    "        'min_length': 1,\n",
    "        'max_length': 2048,\n",
    "    }\n",
    "\n",
    "    input_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "    params = og.GeneratorParams(model)\n",
    "    params.set_search_options(**search_options)\n",
    "    params.input_ids = input_tokens\n",
    "\n",
    "    generator = og.Generator(model, params)\n",
    "\n",
    "    print()\n",
    "    print(\"Output: \", end='', flush=True)\n",
    "\n",
    "    try:\n",
    "        while not generator.is_done():\n",
    "            generator.compute_logits()\n",
    "            generator.generate_next_token()\n",
    "\n",
    "            new_token = generator.get_next_tokens()[0]\n",
    "            print(tokenizer_stream.decode(new_token), end='', flush=True)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"  --control+c pressed, aborting generation--\")\n",
    "\n",
    "    # Delete the generator to free the captured graph for the next generator, if graph capture is enabled\n",
    "    del generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c357dad-51a9-427a-a325-f20c2f235a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantized_model, tokenizer = load_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a69505-2d73-44d8-aee5-ff09d1a56f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:  To answer the question \"What does ASTM stand for?\", I will follow these steps:\n",
      "\n",
      "1. Identify the acronym \"ASTM\" in the context provided.\n",
      "2. Look for any definitions or explanations related to \"ASTM\" in the context.\n",
      "3. Extract the relevant information that defines \"ASTM.\"\n",
      "\n",
      "From the context, I see the following relevant information:\n",
      "\n",
      "##begin_quote##\n",
      "\"ASTM.\"\n",
      "##end_quote##\n",
      "\n",
      "Since the context does not provide a direct definition, I will refer to the general knowledge that ASTM stands for \"American Society for Testing and Materials.\"\n",
      "\n",
      "Final answer: <ANSWER>: ASTM stands for American Society for Testing and Materials."
     ]
    }
   ],
   "source": [
    "run_model(quantized_model, tokenizer, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b7801-3798-4a90-a8d5-a27f1968ba90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03dba8-a7b7-4ef2-9698-240da36f0ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce649a5-3c0d-43ce-81fe-49113eb04786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 19:07:39,254 accelerate.utils.modeling [INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:52<00:00, 28.13s/it]\n"
     ]
    }
   ],
   "source": [
    "pytorch_model = AutoModelForCausalLM.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "pytorch_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62b1d62-966f-458a-a895-fea592e7149e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytorch_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat does ASTM stand for?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m messages \u001b[38;5;241m=\u001b[39m get_chat_template_input(meta_prompt, context, query)\n\u001b[0;32m---> 14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpytorch_tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     15\u001b[0m   messages,\n\u001b[1;32m     16\u001b[0m   tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m   add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m   return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m   return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m pytorch_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(pytorch_tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[:, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pytorch_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "meta_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, clever, friendly and gives concise and accurate answers.\"\n",
    "chunks = [\n",
    "    \"Various. Verify the error codes in the balance\\u2019s manual.MAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n29BASIC DEFINITIONS\\nASTM. American Society of Testing and Materials.\",\n",
    "    \"Preventive maintenance\\nFrequency: Quarterly1. Verify the stability of the lamp. Use the calibration plate, \\nconducting readings with intervals of 30 minutes with the same plate. Compare readings. There must be no diff erences.\",\n",
    "    \"2. A measuring device known as \\u201cload cell\\u201d produces an \\nexit signal corresponding to the load\\u2019s force in the form of changes in the voltage or frequency. 3. A digital analogous electronic circuit shows the fi  nal \\nresult of the weight digitally. Laboratory balances operate according to the principle \\nof compensation of the electromagnetic force applicable to displacements or torques. The combination of their mechanical components and automatic reading systems provides weight measurements at defi  ned levels of accuracy \\ndepending on the model. Principle. The mobile parts (weighing plate, support \\ncolumn [a], bobbin, position and load indicator [G] -the object in the process of being weighed-) are maintained in equilibrium by a compensation force [F] equal to the weight. The compensation force is generated by an electrical current through a bobbin in the air gap of a cylindrical electromagnet. The force F is calculated with the equation [F = I x L x B] where: I = electrical intensity, L = total length of the wire of the coil and B = magnetic fl  ow intensity in the \\nelectromagnet\\u2019s air gap.With any change in the load (weight\\/mass), the mobile \\nmechanical system responds by moving vertically a fraction of distance. Detected by a photosensor [e], an electrical signal is sent to the servo-amplifi  er [f]. This changes the \\nfl ow of electrical current passing through the bobbin of the \\nmagnet [c] in such a manner that the mobile system returns to the balanced position upon adjusting of the magnetic fl ow in the electromagnet. Consequently, the weight of \\nthe mass [G] can be measured indirectly at the start of the electrical current fl  ow, which passes through the circuit \\nmeasuring the voltage [V] by means of a precision resistor [R], [V = I x R]. To date, many systems developed use the electronic system for carrying out very exact measurements of mass and weight. The following diagram explains how electronic balances function. Transfer\\nMechanism\\nLoad Cell\\nScreen and\\nSignal ProcessorPFigure 12. Components of electronic balances  \\nG\\nb\\na\\ne\\nfc dR V=I*R\\nIFigure 13. Compensation force principle  \\nMAINTENANCE MANUAL FOR LABORATORY EQUIPMENT\\n25The signal processing system\\nThe signal processing system is composed of the circuit which \\ntransf orms the electrical signal emitted by the transducer \\ninto numerical data which can be read on a screen. The signal process comprises the following functions:1. Tare setting. This setting is used to adjust the reading \\nvalue at zero with any load within the balance\\u2019s capacity range. It is controlled by a button generally located on the front part of the balance. It is commonly used for taring the weighing container. 2. Repeatability setting control. During a reading, weighed \\nvalues are averaged within a predefi  ned period of time. This function is very useful when weighing operations need to be carried out in unstable conditions, e.g. in the presence of air currents or vibrations. This control defi nes the time period allowed for a result to lie within \\npreset limits for it to be considered stable. In addition, it can be adjusted to suit a particular application.\",\n",
    "    \"Any spill must be cleaned immediately to avoid corrosion \\nor contamination. Use 70% ethanol to disinfect the pan of the balance. Very important:  Never lubricate a balance unless the \\nmanufacturer has expressly indicated it. Any substance interfering with the mechanism of the balance retards its response or defi  nitely alters the measurement process. Note:  In general, the manufacturer or the specialized \\ninstallation representative carries out the maintenance of the balances, according to procedures which vary depending on the type and model. 1 Guidelines for calibration in laboratories, Drinking Water Inspectorate by \\nLGC (Teddington) Ltd., December 2000. CapacityResolution\\n100 g 10 g 1 g 100 mg 10 mg 1 mg 0.1 mg \\u00980.01 mg \\nUp to 200 g \\u2013 \\u2013 \\u2013 M1 M1 F2 F1 F2\\n200 g to 1 kg \\u2013 \\u2013 M1 M1 F2 F1\\/E2 E2 E2\\n1 to 30 kg M2 M2 M1 F2 E2 E2 E2 \\u2013\\n30 to 100 kg M2 M1 F2 F1 E2 \\u2013 \\u2013 \\u2013\\nMore than \\n100 kgM2 M1\\/F2 F1 E2 \\u2013 \\u2013 \\u2013 \\u2013Table of standard weights\\u2019 use according to the balance\\u2019s capacity  CHAPTER 4  BALANCES\\n28FUNCTIONAL ERROR PROBABLE CAUSE\\nReadings not reproducible (hysteresis). The measurement cell is dirty.\",\n",
    "    \"Check the lubrication state of elements such as for \\nO-rings as the manufacturer recommends. Always use lubricants according to the manufacturer\\u2019s instructions (frequency and type of lubricants). In recently manufactured centrifuges, there are sealed ball bearings which do not require lubrication. 5.\",\n",
    "    \"Remove the cover of the boiling tank.3. Visually verify if the interior walls or the immersion \\nresistors show solid deposits or sediments. The quantity of deposits present depends on the quality of water fed to the distiller. If there is an accumulation of sediments, it must be cleaned to avoid damaging the resistors\\n1. 4.\"\n",
    "]\n",
    "context = get_formatted_context(chunks)\n",
    "query = \"What does ASTM stand for?\"\n",
    "messages = get_chat_template_input(meta_prompt, context, query)\n",
    "\n",
    "inputs = pytorch_tokenizer.apply_chat_template(\n",
    "  messages,\n",
    "  tokenize=True,\n",
    "  add_generation_prompt=True,\n",
    "  return_tensors=\"pt\",\n",
    "  return_dict=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = pytorch_model.generate(**inputs, do_sample=True, max_new_tokens=512)\n",
    "print(pytorch_tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969b951-9e15-4581-8caa-baf09f76c059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70728eac-f84d-4d85-b37e-09a86a71d480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOW BENCHMARK:\n",
    "# https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/models/llama/benchmark_e2e.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
