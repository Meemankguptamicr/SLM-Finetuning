$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

name: finetune_model
display_name: Finetune Model
tags:
  author: sfta-team

inputs:
  run_name:
    type: string
  train_file:
    type: uri_file
  base_model_id:
    type: string
    optional: true
  quantization_aware_training:
    type: boolean
    optional: true
  flash_attention:
    type: boolean
    optional: true
  peft_approach:
    type: string
    optional: true
  finetune_approach:
    type: string
    optional: true
  optimizer:
    type: string
    optional: true
  max_seq_length:
    type: integer
    optional: true
  num_train_epochs:
    type: integer
    optional: true
  learning_rate:
    type: number
    optional: true
  per_device_train_batch_size:
    type: integer
    optional: true
  per_device_eval_batch_size:
    type: integer
    optional: true
  gradient_accumulation_steps:
    type: integer
    optional: true
  gradient_checkpointing:
    type: boolean
    optional: true
  logging_steps:
    type: integer
    optional: true
  save_steps:
    type: integer
    optional: true
  eval_steps:
    type: integer
    optional: true
  use_mlflow:
    type: boolean
    optional: true

outputs:
  model_dir:
    type: uri_folder

code: ..

environment: azureml:gpu-finetuning-environment@latest

command: >-
  export PYTHONPATH=$PYTHONPATH:./common/src &&
  python finetuning/finetune_model.py
  --run-name ${{inputs.run_name}}
  --train-file ${{inputs.train_file}}
  $[[--base-model-id ${{inputs.base_model_id}}]]
  $[[--quantization-aware-training ${{inputs.quantization_aware_training}}]]
  $[[--flash-attention ${{inputs.flash_attention}}]]
  $[[--peft-approach ${{inputs.peft_approach}}]]
  $[[--finetune-approach ${{inputs.finetune_approach}}]]
  $[[--optimizer ${{inputs.optimizer}}]]
  $[[--max-seq-length ${{inputs.max_seq_length}}]]
  $[[--num-train-epochs ${{inputs.num_train_epochs}}]]
  $[[--learning-rate ${{inputs.learning_rate}}]]
  $[[--per-device-train-batch-size ${{inputs.per_device_train_batch_size}}]]
  $[[--per-device-eval-batch-size ${{inputs.per_device_eval_batch_size}}]]
  $[[--gradient-accumulation-steps ${{inputs.gradient_accumulation_steps}}]]
  $[[--gradient-checkpointing ${{inputs.gradient_checkpointing}}]]
  $[[--logging-steps ${{inputs.logging_steps}}]]
  $[[--save-steps ${{inputs.save_steps}}]]
  $[[--eval-steps ${{inputs.eval_steps}}]]
  $[[--use-mlflow ${{inputs.use_mlflow}}]]
  --model-dir ${{outputs.model_dir}}