{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efaef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azureml-widgets\n",
    "#%pip install mlflow\n",
    "#%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bc234",
   "metadata": {},
   "source": [
    "## 1. Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ca723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.ai.ml.entities import Environment, BuildContext, AmlCompute, ComputeInstance\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.core.exceptions import ResourceNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37247b2f",
   "metadata": {},
   "source": [
    "## 2. Get a Handle to the Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a196fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    # This will open a browser page for\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381b6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "ml_client = MLClient.from_config(\n",
    "    credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8964cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "azureml_tracking_uri = ml_client.workspaces.get(\n",
    "    ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(azureml_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15fb8f",
   "metadata": {},
   "source": [
    "## 3. Create the Compute Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3d36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute instance.\n"
     ]
    }
   ],
   "source": [
    "# Compute for fine-tuning\n",
    "compute_cluster = False\n",
    "compute_version = \"nc24ads-a100-v4\" #\"std-nc12s-v3\"\n",
    "compute_type = \"Standard_NC24ads_A100_v4\" #\"Standard_NC12s_v3\"\n",
    "\n",
    "if compute_cluster:\n",
    "    gpu_compute_name = f\"{compute_version}-cluster\"\n",
    "    try:\n",
    "        _ = ml_client.compute.get(gpu_compute_name)\n",
    "        print(\"Found existing compute cluster.\")\n",
    "    except ResourceNotFoundError:\n",
    "        print(\"Creating a new compute cluster...\")\n",
    "        compute_config = AmlCompute(\n",
    "            name=gpu_compute_name,\n",
    "            type=\"amlcompute\",\n",
    "            size=compute_type,\n",
    "            idle_time_before_scale_down=120,\n",
    "            min_instances=0,\n",
    "            max_instances=4,\n",
    "        )\n",
    "        ml_client.begin_create_or_update(compute_config).result()\n",
    "else:\n",
    "    gpu_compute_name = f\"{compute_version}-instance\"\n",
    "    try:\n",
    "        _ = ml_client.compute.get(gpu_compute_name)\n",
    "        print(\"Found existing compute instance.\")\n",
    "    except ResourceNotFoundError:\n",
    "        print(\"Creating a new compute instance...\")\n",
    "        compute_config = ComputeInstance(\n",
    "            name=gpu_compute_name,\n",
    "            size=compute_type\n",
    "        )\n",
    "        ml_client.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73644081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute cluster.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline level compute\n",
    "compute_cluster = True\n",
    "compute_type = \"Standard_DS3_v2\" #\"Standard_NC12s_v3\"\n",
    "pipeline_level_compute_name = \"cpu-cluster\"\n",
    "\n",
    "if compute_cluster:\n",
    "    try:\n",
    "        _ = ml_client.compute.get(pipeline_level_compute_name)\n",
    "        print(\"Found existing compute cluster.\")\n",
    "    except ResourceNotFoundError:\n",
    "        print(\"Creating a new compute cluster...\")\n",
    "        compute_config = AmlCompute(\n",
    "            name=pipeline_level_compute_name,\n",
    "            type=\"amlcompute\",\n",
    "            size=compute_type,\n",
    "            idle_time_before_scale_down=120,\n",
    "            min_instances=0,\n",
    "            max_instances=4,\n",
    "        )\n",
    "        ml_client.begin_create_or_update(compute_config).result()\n",
    "else:\n",
    "    try:\n",
    "        _ = ml_client.compute.get(pipeline_level_compute_name)\n",
    "        print(\"Found existing compute instance.\")\n",
    "    except ResourceNotFoundError:\n",
    "        print(\"Creating a new compute instance...\")\n",
    "        compute_config = ComputeInstance(\n",
    "            name=pipeline_level_compute_name,\n",
    "            size=compute_type\n",
    "        )\n",
    "        ml_client.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c4b77",
   "metadata": {},
   "source": [
    "## 4. Create the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e12e097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'msft-raft-finetuning-env', 'description': 'Environment for SLM Fine-tuning', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': True, 'id': '/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourceGroups/lianatests/providers/Microsoft.MachineLearningServices/workspaces/humpbackwhales-aml/environments/msft-raft-finetuning-env/versions/40', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/linapalk2/code/Users/linapalk/RAFT/raft_finetuning_pipeline', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8268ef3370>, 'serialize': <msrest.serialization.Serializer object at 0x7f8268ef3250>, 'version': '40', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7f8268ef30d0>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_docker_context = Environment(\n",
    "    build=BuildContext(path=\"docker_image\"),\n",
    "    name=\"msft-raft-finetuning-env\",\n",
    "    description=\"Environment for SLM Fine-tuning\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c6781",
   "metadata": {},
   "source": [
    "## 6. Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0f6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \".\"\n",
    "finetune_model_func = load_component(source=parent_dir + \"/finetune-model.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbc2846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline()\n",
    "def finetune_model():\n",
    "    inputs = {\n",
    "        \"train_file\": Input(\n",
    "            type=AssetTypes.URI_FILE, path=\"./data/custom-ft.train.jsonl\" #\"./data/raft_sample_data-ft.train.jsonl\"\n",
    "        ),\n",
    "        \"test_file\": Input(\n",
    "            type=AssetTypes.URI_FILE, path=\"./data/custom-ft.valid.jsonl\" #\"./data/raft_sample_data-ft.valid.jsonl\"\n",
    "        ),\n",
    "        \"base_model_id\": \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "        \"model_version\": \"phi3-mini-128K-instruct\"\n",
    "    }\n",
    "    \n",
    "    outputs = {\n",
    "        \"model_dir\": Output(type=AssetTypes.URI_FOLDER)\n",
    "    }\n",
    "\n",
    "    train_model = finetune_model_func(\n",
    "        train_file=inputs[\"train_file\"],\n",
    "        test_file=inputs[\"test_file\"],\n",
    "        base_model_id=inputs[\"base_model_id\"],\n",
    "        model_version=inputs[\"model_version\"]\n",
    "    )\n",
    "    train_model.compute = gpu_compute_name\n",
    "    \n",
    "    return {\"model_dir\": train_model.outputs.model_dir}\n",
    "\n",
    "\n",
    "pipeline_job = finetune_model()\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = pipeline_level_compute_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02e6ec",
   "metadata": {},
   "source": [
    "## 7. Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34aaadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.02 MBs): 100%|██████████| 22607/22607 [00:00<00:00, 636234.89it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>raft-phi3-finetuning</td><td>polite_brick_7t7n59tl5x</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/polite_brick_7t7n59tl5x?wsid=/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourcegroups/lianatests/workspaces/humpbackwhales-aml&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {'model_dir': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7f8268c11390>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/linapalk2/code/Users/linapalk/RAFT/raft_finetuning_pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f8268c11150>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'finetune_model', 'is_deterministic': None, 'inputs': {}, 'outputs': {'model_dir': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'train_model': Command({'parameters': {}, 'init': False, 'name': 'train_model', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/linapalk2/code/Users/linapalk/RAFT/raft_finetuning_pipeline', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f8268c11180>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': 'nc24ads-a100-v4-instance', 'services': None, 'comment': None, 'job_inputs': {'train_file': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/4d8e131d36a53e10d873579f29dfc67e/custom-ft.train.jsonl'}, 'test_file': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d7dedaaa4c65e3798aa3c4486c74a3b9/custom-ft.valid.jsonl'}, 'base_model_id': 'microsoft/Phi-3-mini-128k-instruct', 'model_version': 'phi3-mini-128K-instruct'}, 'job_outputs': {'model_dir': '${{parent.outputs.model_dir}}'}, 'inputs': {'train_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8268c11060>, 'test_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8268c11540>, 'base_model_id': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8268c11510>, 'model_version': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8268c110f0>}, 'outputs': {'model_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f8268c10eb0>}, 'component': 'azureml_anonymous:e016e279-6b12-4ba7-ac3f-d1686f4dd0c8', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '2e3b66b7-45f1-4cb8-80ef-9016c6e5fa57', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f8268c11030>, 'environment_variables': {}, 'environment': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'polite_brick_7t7n59tl5x', 'description': None, 'tags': {}, 'properties': {'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'cpu-cluster', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourceGroups/lianatests/providers/Microsoft.MachineLearningServices/workspaces/humpbackwhales-aml/jobs/polite_brick_7t7n59tl5x', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/linapalk2/code/Users/linapalk/RAFT/raft_finetuning_pipeline', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8268c10df0>, 'serialize': <msrest.serialization.Serializer object at 0x7f8268c113f0>, 'display_name': 'finetune_model', 'experiment_name': 'raft-phi3-finetuning', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourceGroups/lianatests/providers/Microsoft.MachineLearningServices/workspaces/humpbackwhales-aml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/polite_brick_7t7n59tl5x?wsid=/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourcegroups/lianatests/workspaces/humpbackwhales-aml&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"raft-phi3-finetuning\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c13b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: polite_brick_7t7n59tl5x\n",
      "Web View: https://ml.azure.com/runs/polite_brick_7t7n59tl5x?wsid=/subscriptions/03fd01f6-6051-4545-a78e-ceaace399b96/resourcegroups/lianatests/workspaces/humpbackwhales-aml\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-09-19 21:11:45Z] Submitting 1 runs, first five are: 5cf535de:30f4af6f-5cc2-4eec-ba59-e4cb0cf94d46\n"
     ]
    }
   ],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a249a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
